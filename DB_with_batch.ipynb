{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07c76602-8e5a-47aa-9eda-23641aeef621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:03.540610375Z",
     "start_time": "2023-12-19T17:59:03.505879745Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import functools\n",
    "from itertools import product\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f2a7f88d-e4e4-4fd1-af9c-54d04a33c1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:03.615714867Z",
     "start_time": "2023-12-19T17:59:03.615332802Z"
    }
   },
   "outputs": [],
   "source": [
    "D = 4\n",
    "H = 8\n",
    "R0 = 0.1\n",
    "batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "def reward(pos: torch.Tensor):\n",
    "    reward_ = R0\n",
    "    reward_ += functools.reduce(lambda a, b: a * b, [0.25 < abs(pos[d] / (H - 1) - 0.5) <= 0.5 for d in range(D)])\n",
    "    reward_ += functools.reduce(lambda a, b: a * b, [0.30 < abs(pos[d] / (H - 1) - 0.5) < 0.4 for d in range(D)])\n",
    "    return reward_\n",
    "\n",
    "\n",
    "rewards = torch.zeros(*[H for i in range(D)])\n",
    "coords = [range(H) for _ in range(D)]\n",
    "\n",
    "for coord in product(*coords):\n",
    "    rewards[tuple(coord)] = reward(torch.tensor(coord))\n",
    "\n",
    "rewards /= rewards.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:04.842402411Z",
     "start_time": "2023-12-19T17:59:04.180894940Z"
    }
   },
   "id": "e60ff5db21b90e52"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "99ea75a3-67a2-403d-b611-a531238b4e34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:05.400214743Z",
     "start_time": "2023-12-19T17:59:05.393670369Z"
    }
   },
   "outputs": [],
   "source": [
    "class GFlowNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidded_size = hidden_size\n",
    "        self.linear_1 = nn.Linear(D * H, self.hidded_size)\n",
    "        self.linear_2 = nn.Linear(self.hidded_size, D + 2)\n",
    "\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        pred = self.activation(self.linear_1(x))\n",
    "        pred = self.linear_2(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "model1 = GFlowNet(128)\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "def code(state):\n",
    "    res = torch.zeros(batch, H * D)\n",
    "    for k in range(batch):\n",
    "        for d in range(D):\n",
    "            res[k][int(state[k][d]) + d * H] = 1.0\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:06.006840209Z",
     "start_time": "2023-12-19T17:59:05.998854306Z"
    }
   },
   "id": "e296c4d4e9c53ca"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "def empirical_loss(samples):\n",
    "    counter = torch.zeros(*[H for i in range(D)])\n",
    "    for sample in samples:\n",
    "        counter[tuple(sample)] += 1\n",
    "    counter /= counter.sum()\n",
    "    return (rewards - counter).abs().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:06.650639672Z",
     "start_time": "2023-12-19T17:59:06.642257399Z"
    }
   },
   "id": "5812bd07741444b"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "720e19e3-a941-4814-817a-ceddaa048934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:21.392432778Z",
     "start_time": "2023-12-19T17:59:21.363572866Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model: GFlowNet, optimizer, loss_fn, n_epochs):\n",
    "    visited = []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = loss_fn(model)\n",
    "        loss = x[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for state in x[1]:\n",
    "            visited.append(state)\n",
    "\n",
    "        if epoch % 50 == 0: print(f\"Epoch {epoch}, loss = {empirical_loss(visited[-20000:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "def pred_next(probs, is_sampled, states):\n",
    "    nxt = torch.distributions.categorical.Categorical(probs).sample()\n",
    "\n",
    "    correct = True\n",
    "    for k in range(batch):\n",
    "        if is_sampled[k] or nxt[k] == D: continue\n",
    "        if states[k][nxt[k]] == H - 1: correct = False\n",
    "\n",
    "    if not correct: return pred_next(probs, is_sampled, states)\n",
    "    return nxt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:22.091038412Z",
     "start_time": "2023-12-19T17:59:22.081786656Z"
    }
   },
   "id": "9fb3cb407fdc91dd"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def detailed_balance_loss(model: GFlowNet):\n",
    "    is_sampled = torch.zeros(batch)\n",
    "    states = torch.zeros(batch, D, dtype=torch.int64)\n",
    "    ways = [[] for i in range(batch)]\n",
    "\n",
    "    finished = False\n",
    "    while not finished:\n",
    "        pred = model(code(states))\n",
    "        probs = pred[:, 0: -1]\n",
    "        flow = pred[:, -1]\n",
    "\n",
    "        finished = True\n",
    "        for j in range(0, batch):\n",
    "            if is_sampled[j]: continue\n",
    "            finished = False\n",
    "            for i in range(0, D):\n",
    "                if states[j][i] == H - 1:\n",
    "                    probs[j][i] = -float(\"inf\")\n",
    "\n",
    "        probs = torch.nn.Softmax(dim=1)(probs)\n",
    "\n",
    "        nxt = pred_next(probs, is_sampled, states)\n",
    "\n",
    "        for k in range(0, batch):\n",
    "            if is_sampled[k]: continue\n",
    "            cnt_b = max(1, functools.reduce(lambda x, y: x + (y >= 1), states[k]))\n",
    "            ways[k].append([flow[k], probs[k][nxt[k]].log(), math.log(1 / cnt_b)])\n",
    "            if nxt[k] == D:\n",
    "                ways[k].append([math.log(reward(states[k])), 0, 0])\n",
    "                is_sampled[k] = True\n",
    "            else:\n",
    "                states[k][nxt[k]] += 1\n",
    "\n",
    "    loss = 0\n",
    "    for j in range(batch):\n",
    "        for i in range(0, len(ways[j]) - 1):\n",
    "            loss += (ways[j][i][0] + ways[j][i][1] - ways[j][i + 1][0] - ways[j][i + 1][2]) ** 2\n",
    "    loss /= batch\n",
    "    \n",
    "    return loss, states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T17:59:22.559144921Z",
     "start_time": "2023-12-19T17:59:22.552098445Z"
    }
   },
   "id": "184ea20d791b40cb"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, loss = 1.8829225301742554\n",
      "Epoch 100, loss = 1.836082100868225\n",
      "Epoch 150, loss = 1.7919085025787354\n",
      "Epoch 200, loss = 1.7343473434448242\n",
      "Epoch 250, loss = 1.6825450658798218\n",
      "Epoch 300, loss = 1.62959885597229\n",
      "Epoch 350, loss = 1.5723975896835327\n",
      "Epoch 400, loss = 1.5110070705413818\n",
      "Epoch 450, loss = 1.4572871923446655\n",
      "Epoch 500, loss = 1.4095252752304077\n",
      "Epoch 550, loss = 1.3659405708312988\n",
      "Epoch 600, loss = 1.3230280876159668\n",
      "Epoch 650, loss = 1.2846542596817017\n",
      "Epoch 700, loss = 1.2519886493682861\n",
      "Epoch 750, loss = 1.2312843799591064\n",
      "Epoch 800, loss = 1.2120141983032227\n",
      "Epoch 850, loss = 1.1957565546035767\n",
      "Epoch 900, loss = 1.1803474426269531\n",
      "Epoch 950, loss = 1.1628798246383667\n",
      "Epoch 1000, loss = 1.1514924764633179\n",
      "Epoch 1050, loss = 1.1411404609680176\n",
      "Epoch 1100, loss = 1.1320475339889526\n",
      "Epoch 1150, loss = 1.1205109357833862\n",
      "Epoch 1200, loss = 1.1133849620819092\n",
      "Epoch 1250, loss = 1.104933500289917\n",
      "Epoch 1300, loss = 1.095579981803894\n",
      "Epoch 1350, loss = 1.0885746479034424\n",
      "Epoch 1400, loss = 1.0838682651519775\n",
      "Epoch 1450, loss = 1.0809284448623657\n",
      "Epoch 1500, loss = 1.0781704187393188\n",
      "Epoch 1550, loss = 1.0743329524993896\n",
      "Epoch 1600, loss = 1.071448802947998\n",
      "Epoch 1650, loss = 1.0667964220046997\n",
      "Epoch 1700, loss = 1.0639365911483765\n",
      "Epoch 1750, loss = 1.0602012872695923\n",
      "Epoch 1800, loss = 1.0556706190109253\n",
      "Epoch 1850, loss = 1.0536137819290161\n",
      "Epoch 1900, loss = 1.05316162109375\n",
      "Epoch 1950, loss = 1.0501033067703247\n",
      "Epoch 2000, loss = 1.0469417572021484\n",
      "Epoch 2050, loss = 1.0468652248382568\n",
      "Epoch 2100, loss = 1.047663927078247\n",
      "Epoch 2150, loss = 1.0474624633789062\n",
      "Epoch 2200, loss = 1.0500820875167847\n",
      "Epoch 2250, loss = 1.0530544519424438\n",
      "Epoch 2300, loss = 1.0546530485153198\n",
      "Epoch 2350, loss = 1.0569003820419312\n",
      "Epoch 2400, loss = 1.0582990646362305\n",
      "Epoch 2450, loss = 1.0585699081420898\n",
      "Epoch 2500, loss = 1.0601422786712646\n",
      "Epoch 2550, loss = 1.0600168704986572\n",
      "Epoch 2600, loss = 1.0612300634384155\n",
      "Epoch 2650, loss = 1.0622708797454834\n",
      "Epoch 2700, loss = 1.0639314651489258\n",
      "Epoch 2750, loss = 1.0658050775527954\n",
      "Epoch 2800, loss = 1.067046046257019\n",
      "Epoch 2850, loss = 1.0679235458374023\n",
      "Epoch 2900, loss = 1.0681074857711792\n",
      "Epoch 2950, loss = 1.0698680877685547\n",
      "Epoch 3000, loss = 1.0734535455703735\n",
      "Epoch 3050, loss = 1.075192928314209\n",
      "Epoch 3100, loss = 1.0762193202972412\n",
      "Epoch 3150, loss = 1.0775797367095947\n",
      "Epoch 3200, loss = 1.0792535543441772\n",
      "Epoch 3250, loss = 1.0786733627319336\n",
      "Epoch 3300, loss = 1.0813746452331543\n",
      "Epoch 3350, loss = 1.0829352140426636\n",
      "Epoch 3400, loss = 1.0838221311569214\n",
      "Epoch 3450, loss = 1.0848482847213745\n",
      "Epoch 3500, loss = 1.0839680433273315\n",
      "Epoch 3550, loss = 1.0854154825210571\n",
      "Epoch 3600, loss = 1.0862629413604736\n",
      "Epoch 3650, loss = 1.086956262588501\n",
      "Epoch 3700, loss = 1.086869478225708\n",
      "Epoch 3750, loss = 1.087815523147583\n",
      "Epoch 3800, loss = 1.0891826152801514\n",
      "Epoch 3850, loss = 1.0897825956344604\n",
      "Epoch 3900, loss = 1.0891155004501343\n",
      "Epoch 3950, loss = 1.0896761417388916\n",
      "Epoch 4000, loss = 1.089869499206543\n",
      "Epoch 4050, loss = 1.090089201927185\n",
      "Epoch 4100, loss = 1.0901694297790527\n",
      "Epoch 4150, loss = 1.0909103155136108\n",
      "Epoch 4200, loss = 1.0912234783172607\n",
      "Epoch 4250, loss = 1.0911694765090942\n",
      "Epoch 4300, loss = 1.0901957750320435\n",
      "Epoch 4350, loss = 1.0902628898620605\n",
      "Epoch 4400, loss = 1.0905431509017944\n",
      "Epoch 4450, loss = 1.0898023843765259\n",
      "Epoch 4500, loss = 1.0888563394546509\n",
      "Epoch 4550, loss = 1.0902905464172363\n",
      "Epoch 4600, loss = 1.0903234481811523\n",
      "Epoch 4650, loss = 1.0904037952423096\n",
      "Epoch 4700, loss = 1.0902299880981445\n",
      "Epoch 4750, loss = 1.0903037786483765\n",
      "Epoch 4800, loss = 1.0914511680603027\n",
      "Epoch 4850, loss = 1.0912643671035767\n",
      "Epoch 4900, loss = 1.0934985876083374\n",
      "Epoch 4950, loss = 1.092131495475769\n",
      "Epoch 5000, loss = 1.091370940208435\n",
      "Epoch 5050, loss = 1.0902234315872192\n",
      "Epoch 5100, loss = 1.090762972831726\n",
      "Epoch 5150, loss = 1.0902023315429688\n",
      "Epoch 5200, loss = 1.0910694599151611\n",
      "Epoch 5250, loss = 1.0917892456054688\n",
      "Epoch 5300, loss = 1.0922497510910034\n",
      "Epoch 5350, loss = 1.0918629169464111\n",
      "Epoch 5400, loss = 1.0923761129379272\n",
      "Epoch 5450, loss = 1.0924432277679443\n",
      "Epoch 5500, loss = 1.0916825532913208\n",
      "Epoch 5550, loss = 1.0917891263961792\n",
      "Epoch 5600, loss = 1.0917956829071045\n",
      "Epoch 5650, loss = 1.0919089317321777\n",
      "Epoch 5700, loss = 1.0925891399383545\n",
      "Epoch 5750, loss = 1.0929169654846191\n",
      "Epoch 5800, loss = 1.09117591381073\n",
      "Epoch 5850, loss = 1.0910694599151611\n",
      "Epoch 5900, loss = 1.0913023948669434\n",
      "Epoch 5950, loss = 1.0912694931030273\n",
      "Epoch 6000, loss = 1.089869499206543\n",
      "Epoch 6050, loss = 1.088402271270752\n",
      "Epoch 6100, loss = 1.088815450668335\n",
      "Epoch 6150, loss = 1.087554931640625\n",
      "Epoch 6200, loss = 1.0863548517227173\n",
      "Epoch 6250, loss = 1.0868483781814575\n",
      "Epoch 6300, loss = 1.0859745740890503\n",
      "Epoch 6350, loss = 1.086881160736084\n",
      "Epoch 6400, loss = 1.086674690246582\n",
      "Epoch 6450, loss = 1.086535096168518\n",
      "Epoch 6500, loss = 1.0866286754608154\n",
      "Epoch 6550, loss = 1.085422158241272\n",
      "Epoch 6600, loss = 1.0853089094161987\n",
      "Epoch 6650, loss = 1.085402250289917\n",
      "Epoch 6700, loss = 1.0850892066955566\n",
      "Epoch 6750, loss = 1.0864759683609009\n",
      "Epoch 6800, loss = 1.086936593055725\n",
      "Epoch 6850, loss = 1.086836576461792\n",
      "Epoch 6900, loss = 1.0877103805541992\n",
      "Epoch 6950, loss = 1.089031457901001\n",
      "Epoch 7000, loss = 1.0891709327697754\n",
      "Epoch 7050, loss = 1.0902905464172363\n",
      "Epoch 7100, loss = 1.0900037288665771\n",
      "Epoch 7150, loss = 1.0891709327697754\n",
      "Epoch 7200, loss = 1.0881905555725098\n",
      "Epoch 7250, loss = 1.0868432521820068\n",
      "Epoch 7300, loss = 1.0874431133270264\n",
      "Epoch 7350, loss = 1.0877432823181152\n",
      "Epoch 7400, loss = 1.0871891975402832\n",
      "Epoch 7450, loss = 1.0874892473220825\n",
      "Epoch 7500, loss = 1.0888628959655762\n",
      "Epoch 7550, loss = 1.0882892608642578\n",
      "Epoch 7600, loss = 1.0899299383163452\n",
      "Epoch 7650, loss = 1.0898628234863281\n",
      "Epoch 7700, loss = 1.0906299352645874\n",
      "Epoch 7750, loss = 1.0921366214752197\n",
      "Epoch 7800, loss = 1.0921971797943115\n",
      "Epoch 7850, loss = 1.0911905765533447\n",
      "Epoch 7900, loss = 1.0916708707809448\n",
      "Epoch 7950, loss = 1.0918643474578857\n",
      "Epoch 8000, loss = 1.093351125717163\n",
      "Epoch 8050, loss = 1.093857765197754\n",
      "Epoch 8100, loss = 1.0929971933364868\n",
      "Epoch 8150, loss = 1.093003749847412\n",
      "Epoch 8200, loss = 1.0936037302017212\n",
      "Epoch 8250, loss = 1.0937905311584473\n",
      "Epoch 8300, loss = 1.0942037105560303\n",
      "Epoch 8350, loss = 1.092716932296753\n",
      "Epoch 8400, loss = 1.0937775373458862\n",
      "Epoch 8450, loss = 1.0926905870437622\n",
      "Epoch 8500, loss = 1.094177484512329\n",
      "Epoch 8550, loss = 1.0944972038269043\n",
      "Epoch 8600, loss = 1.0932233333587646\n",
      "Epoch 8650, loss = 1.0937234163284302\n",
      "Epoch 8700, loss = 1.0946708917617798\n",
      "Epoch 8750, loss = 1.0937577486038208\n",
      "Epoch 8800, loss = 1.094957709312439\n",
      "Epoch 8850, loss = 1.0951642990112305\n",
      "Epoch 8900, loss = 1.0942840576171875\n",
      "Epoch 8950, loss = 1.095110297203064\n",
      "Epoch 9000, loss = 1.094130039215088\n",
      "Epoch 9050, loss = 1.0937432050704956\n",
      "Epoch 9100, loss = 1.094590663909912\n",
      "Epoch 9150, loss = 1.0950840711593628\n",
      "Epoch 9200, loss = 1.0937708616256714\n",
      "Epoch 9250, loss = 1.0947511196136475\n",
      "Epoch 9300, loss = 1.0933773517608643\n",
      "Epoch 9350, loss = 1.0939379930496216\n",
      "Epoch 9400, loss = 1.094164252281189\n",
      "Epoch 9450, loss = 1.0943511724472046\n",
      "Epoch 9500, loss = 1.0934511423110962\n",
      "Epoch 9550, loss = 1.094111680984497\n",
      "Epoch 9600, loss = 1.0938117504119873\n",
      "Epoch 9650, loss = 1.092970848083496\n",
      "Epoch 9700, loss = 1.0937708616256714\n",
      "Epoch 9750, loss = 1.0933576822280884\n",
      "Epoch 9800, loss = 1.0944314002990723\n",
      "Epoch 9850, loss = 1.0959722995758057\n",
      "Epoch 9900, loss = 1.0953855514526367\n",
      "Epoch 9950, loss = 1.0955854654312134\n",
      "Epoch 10000, loss = 1.094405174255371\n"
     ]
    }
   ],
   "source": [
    "train(model1, optimizer1, detailed_balance_loss, 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T18:05:42.239710618Z",
     "start_time": "2023-12-19T17:59:23.250624452Z"
    }
   },
   "id": "d6341af75d964743"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ffe03e4b52a05751"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
